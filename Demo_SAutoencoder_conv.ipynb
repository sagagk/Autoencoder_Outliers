{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def explained_variance_score(y_true,y_pred):\n",
    "    error = y_true - y_pred\n",
    "    var_error = K.sum(K.square(error - K.mean(error)))\n",
    "    var_true = K.sum(K.square(y_true - K.mean(y_pred)))\n",
    "    return (1 - (var_error/var_true))\n",
    "\n",
    "\n",
    "def r2(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred))\n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()))\n",
    "\n",
    "def autoencoder(input_shape):\n",
    "    model = Sequential(name=\"Autoencoder\")\n",
    "    # Encoder\n",
    "    model.add(layers.InputLayer(input_shape= input_shape)) # 240x1x1\n",
    "    model.add(layers.Conv2D(16, kernel_size=(6, 1),strides=(6,1),activation='tanh',padding='valid',name=\"conv_1\")) # 40x1x16   \n",
    "    model.add(layers.Conv2D(32,  kernel_size=(3,1),strides=(2,1),activation='tanh',padding='same',name=\"conv_2\")) # 20x1x32\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3,1),strides=(2,1),activation='tanh',padding='same',name=\"conv_3\")) # 10x1x64 \n",
    "    model.add(layers.Conv2D(128, kernel_size=(3,1),strides=(2,1),activation='tanh',padding='same',name=\"conv_4\")) # 5x1x128    \n",
    "    model.add(layers.Flatten(name=\"flatten_1\")) # 640\n",
    "    # Coding\n",
    "    model.add(layers.Dense(300,activation='tanh',name=\"dense_1\")) # 300\n",
    "    model.add(layers.Dense(640,activation='tanh',name=\"dense_2\")) # 640\n",
    "    # Decoder\n",
    "    model.add(layers.Reshape((5,1,128),name=\"reshape_1\")) # 5x1x128\n",
    "    model.add(layers.Conv2DTranspose(64, kernel_size=(3, 1),strides=(2,1),activation='tanh',padding='same',name=\"deconv_1\")) # 10x1x64\n",
    "    model.add(layers.Conv2DTranspose(32,kernel_size=(3,1), strides=(2, 1), activation='tanh',padding='same',name=\"deconv_2\")) # 20x1x32\n",
    "    model.add(layers.Conv2DTranspose(16,kernel_size=(3,1), strides=(2, 1), activation='tanh',padding='same',name=\"deconv_3\")) # 40x1x16  \n",
    "    model.add(layers.Conv2DTranspose(1,kernel_size=(6,1), strides=(6, 1), activation='tanh',padding='valid',name=\"deconv_4\")) # 240x1x1  \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data (anonymized sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with h5py.File('data_set_5_conv/data_set_5.hdf5', 'a') as data:\n",
    "#    X_train = data[\"Data_train/X_train\"][:]\n",
    "#    X_test = data[\"Data_test/X_test\"][:]\n",
    "    \n",
    "#X_train = np.reshape(X_train, (len(X_train), 240,1, 1))\n",
    "#X_test = np.reshape(X_test, (len(X_test), 240, 1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.load(\"X_train.npy\")\n",
    "X_test=np.load(\"X_test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training y testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  (340964, 240, 1, 1)\n",
      "X_test :  (137782, 240, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train : \",X_train.shape)\n",
    "print(\"X_test : \",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture of autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 40, 1, 16)         112       \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 20, 1, 32)         1568      \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 10, 1, 64)         6208      \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 5, 1, 128)         24704     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               192300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 640)               192640    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 5, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "deconv_1 (Conv2DTranspose)   (None, 10, 1, 64)         24640     \n",
      "_________________________________________________________________\n",
      "deconv_2 (Conv2DTranspose)   (None, 20, 1, 32)         6176      \n",
      "_________________________________________________________________\n",
      "deconv_3 (Conv2DTranspose)   (None, 40, 1, 16)         1552      \n",
      "_________________________________________________________________\n",
      "deconv_4 (Conv2DTranspose)   (None, 240, 1, 1)         97        \n",
      "=================================================================\n",
      "Total params: 449,997\n",
      "Trainable params: 449,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:] \n",
    "model = autoencoder(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1066/1066 [==============================] - 5s 4ms/step - loss: 0.0535 - r2: -0.6156 - explained_variance_score: 0.1929 - val_loss: 0.0332 - val_r2: -0.0465 - val_explained_variance_score: 0.0321\n",
      "Epoch 2/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0334 - r2: 7.7726e-04 - explained_variance_score: 0.0365 - val_loss: 0.0331 - val_r2: -0.0457 - val_explained_variance_score: 0.0314\n",
      "Epoch 3/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0333 - r2: 0.0032 - explained_variance_score: 0.0411 - val_loss: 0.0329 - val_r2: -0.0394 - val_explained_variance_score: 0.0280\n",
      "Epoch 4/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0327 - r2: 0.0109 - explained_variance_score: 0.0487 - val_loss: 0.0329 - val_r2: -0.0391 - val_explained_variance_score: 0.0341\n",
      "Epoch 5/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0330 - r2: 0.0151 - explained_variance_score: 0.0513 - val_loss: 0.0327 - val_r2: -0.0334 - val_explained_variance_score: 0.0376\n",
      "Epoch 6/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0326 - r2: 0.0190 - explained_variance_score: 0.0581 - val_loss: 0.0326 - val_r2: -0.0297 - val_explained_variance_score: 0.0461\n",
      "Epoch 7/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0323 - r2: 0.0300 - explained_variance_score: 0.0631 - val_loss: 0.0322 - val_r2: -0.0170 - val_explained_variance_score: 0.0519\n",
      "Epoch 8/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0321 - r2: 0.0381 - explained_variance_score: 0.0751 - val_loss: 0.0318 - val_r2: -0.0037 - val_explained_variance_score: 0.0652\n",
      "Epoch 9/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0316 - r2: 0.0553 - explained_variance_score: 0.0842 - val_loss: 0.0312 - val_r2: 0.0149 - val_explained_variance_score: 0.0891\n",
      "Epoch 10/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0306 - r2: 0.0799 - explained_variance_score: 0.1117 - val_loss: 0.0298 - val_r2: 0.0590 - val_explained_variance_score: 0.1262\n",
      "Epoch 11/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0289 - r2: 0.1253 - explained_variance_score: 0.1578 - val_loss: 0.0268 - val_r2: 0.1539 - val_explained_variance_score: 0.2036\n",
      "Epoch 12/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0256 - r2: 0.2307 - explained_variance_score: 0.2581 - val_loss: 0.0206 - val_r2: 0.3482 - val_explained_variance_score: 0.3825\n",
      "Epoch 13/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0187 - r2: 0.4385 - explained_variance_score: 0.4528 - val_loss: 0.0134 - val_r2: 0.5782 - val_explained_variance_score: 0.5938\n",
      "Epoch 14/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0116 - r2: 0.6492 - explained_variance_score: 0.6557 - val_loss: 0.0070 - val_r2: 0.7782 - val_explained_variance_score: 0.7798\n",
      "Epoch 15/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0063 - r2: 0.8117 - explained_variance_score: 0.8143 - val_loss: 0.0040 - val_r2: 0.8733 - val_explained_variance_score: 0.8737\n",
      "Epoch 16/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0038 - r2: 0.8849 - explained_variance_score: 0.8861 - val_loss: 0.0029 - val_r2: 0.9094 - val_explained_variance_score: 0.9097\n",
      "Epoch 17/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0028 - r2: 0.9150 - explained_variance_score: 0.9159 - val_loss: 0.0023 - val_r2: 0.9281 - val_explained_variance_score: 0.9284\n",
      "Epoch 18/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0023 - r2: 0.9308 - explained_variance_score: 0.9315 - val_loss: 0.0019 - val_r2: 0.9393 - val_explained_variance_score: 0.9396\n",
      "Epoch 19/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0020 - r2: 0.9409 - explained_variance_score: 0.9415 - val_loss: 0.0017 - val_r2: 0.9468 - val_explained_variance_score: 0.9470\n",
      "Epoch 20/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0017 - r2: 0.9479 - explained_variance_score: 0.9483 - val_loss: 0.0015 - val_r2: 0.9521 - val_explained_variance_score: 0.9523\n",
      "Epoch 21/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0016 - r2: 0.9526 - explained_variance_score: 0.9530 - val_loss: 0.0014 - val_r2: 0.9562 - val_explained_variance_score: 0.9563\n",
      "Epoch 22/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0014 - r2: 0.9568 - explained_variance_score: 0.9572 - val_loss: 0.0013 - val_r2: 0.9593 - val_explained_variance_score: 0.9594\n",
      "Epoch 23/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0013 - r2: 0.9596 - explained_variance_score: 0.9600 - val_loss: 0.0012 - val_r2: 0.9618 - val_explained_variance_score: 0.9619\n",
      "Epoch 24/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0013 - r2: 0.9615 - explained_variance_score: 0.9618 - val_loss: 0.0011 - val_r2: 0.9639 - val_explained_variance_score: 0.9641\n",
      "Epoch 25/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0012 - r2: 0.9639 - explained_variance_score: 0.9642 - val_loss: 0.0011 - val_r2: 0.9656 - val_explained_variance_score: 0.9658\n",
      "Epoch 26/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0011 - r2: 0.9653 - explained_variance_score: 0.9656 - val_loss: 0.0010 - val_r2: 0.9671 - val_explained_variance_score: 0.9673\n",
      "Epoch 27/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0011 - r2: 0.9666 - explained_variance_score: 0.9669 - val_loss: 0.0010 - val_r2: 0.9685 - val_explained_variance_score: 0.9686\n",
      "Epoch 28/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0011 - r2: 0.9678 - explained_variance_score: 0.9681 - val_loss: 9.6463e-04 - val_r2: 0.9696 - val_explained_variance_score: 0.9697\n",
      "Epoch 29/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0010 - r2: 0.9691 - explained_variance_score: 0.9694 - val_loss: 9.3361e-04 - val_r2: 0.9706 - val_explained_variance_score: 0.9707\n",
      "Epoch 30/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 0.0010 - r2: 0.9697 - explained_variance_score: 0.9699 - val_loss: 9.0566e-04 - val_r2: 0.9714 - val_explained_variance_score: 0.9716\n",
      "Epoch 31/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 9.7805e-04 - r2: 0.9707 - explained_variance_score: 0.9710 - val_loss: 8.8350e-04 - val_r2: 0.9721 - val_explained_variance_score: 0.9722\n",
      "Epoch 32/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 9.6052e-04 - r2: 0.9711 - explained_variance_score: 0.9714 - val_loss: 8.5814e-04 - val_r2: 0.9729 - val_explained_variance_score: 0.9730\n",
      "Epoch 33/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 9.2265e-04 - r2: 0.9722 - explained_variance_score: 0.9725 - val_loss: 8.3757e-04 - val_r2: 0.9736 - val_explained_variance_score: 0.9737\n",
      "Epoch 34/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 9.1373e-04 - r2: 0.9724 - explained_variance_score: 0.9727 - val_loss: 8.2007e-04 - val_r2: 0.9741 - val_explained_variance_score: 0.9743\n",
      "Epoch 35/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 8.9839e-04 - r2: 0.9729 - explained_variance_score: 0.9731 - val_loss: 8.0351e-04 - val_r2: 0.9747 - val_explained_variance_score: 0.9748\n",
      "Epoch 36/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 8.9423e-04 - r2: 0.9734 - explained_variance_score: 0.9736 - val_loss: 7.8750e-04 - val_r2: 0.9752 - val_explained_variance_score: 0.9753\n",
      "Epoch 37/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 8.6612e-04 - r2: 0.9739 - explained_variance_score: 0.9742 - val_loss: 7.7475e-04 - val_r2: 0.9756 - val_explained_variance_score: 0.9757\n",
      "Epoch 38/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 8.4288e-04 - r2: 0.9747 - explained_variance_score: 0.9749 - val_loss: 7.5780e-04 - val_r2: 0.9761 - val_explained_variance_score: 0.9762\n",
      "Epoch 39/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 8.4175e-04 - r2: 0.9748 - explained_variance_score: 0.9750 - val_loss: 7.4646e-04 - val_r2: 0.9765 - val_explained_variance_score: 0.9766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 8.3154e-04 - r2: 0.9750 - explained_variance_score: 0.9752 - val_loss: 7.3486e-04 - val_r2: 0.9768 - val_explained_variance_score: 0.9769\n",
      "Epoch 41/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 8.0852e-04 - r2: 0.9756 - explained_variance_score: 0.9758 - val_loss: 7.2500e-04 - val_r2: 0.9771 - val_explained_variance_score: 0.9772\n",
      "Epoch 42/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 8.0036e-04 - r2: 0.9761 - explained_variance_score: 0.9764 - val_loss: 7.1639e-04 - val_r2: 0.9774 - val_explained_variance_score: 0.9775\n",
      "Epoch 43/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 7.9320e-04 - r2: 0.9762 - explained_variance_score: 0.9764 - val_loss: 7.0685e-04 - val_r2: 0.9777 - val_explained_variance_score: 0.9778\n",
      "Epoch 44/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 7.9399e-04 - r2: 0.9761 - explained_variance_score: 0.9763 - val_loss: 6.9929e-04 - val_r2: 0.9780 - val_explained_variance_score: 0.9781\n",
      "Epoch 45/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 7.6906e-04 - r2: 0.9767 - explained_variance_score: 0.9769 - val_loss: 6.9086e-04 - val_r2: 0.9782 - val_explained_variance_score: 0.9783\n",
      "Epoch 46/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 7.6864e-04 - r2: 0.9770 - explained_variance_score: 0.9772 - val_loss: 6.8264e-04 - val_r2: 0.9785 - val_explained_variance_score: 0.9786\n",
      "Epoch 47/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 7.6012e-04 - r2: 0.9772 - explained_variance_score: 0.9774 - val_loss: 6.7594e-04 - val_r2: 0.9787 - val_explained_variance_score: 0.9788\n",
      "Epoch 48/100\n",
      "1066/1066 [==============================] - 4s 4ms/step - loss: 7.6321e-04 - r2: 0.9771 - explained_variance_score: 0.9773 - val_loss: 6.6935e-04 - val_r2: 0.9789 - val_explained_variance_score: 0.9790\n",
      "Epoch 49/100\n",
      "1066/1066 [==============================] - 4s 4ms/step - loss: 7.5453e-04 - r2: 0.9774 - explained_variance_score: 0.9776 - val_loss: 6.6131e-04 - val_r2: 0.9792 - val_explained_variance_score: 0.9792\n",
      "Epoch 50/100\n",
      "1066/1066 [==============================] - 4s 4ms/step - loss: 7.3517e-04 - r2: 0.9778 - explained_variance_score: 0.9780 - val_loss: 6.5632e-04 - val_r2: 0.9793 - val_explained_variance_score: 0.9794\n",
      "Epoch 51/100\n",
      "1066/1066 [==============================] - 4s 3ms/step - loss: 7.3407e-04 - r2: 0.9779 - explained_variance_score: 0.9780 - val_loss: 6.5133e-04 - val_r2: 0.9795 - val_explained_variance_score: 0.9796\n",
      "Epoch 52/100\n",
      "1066/1066 [==============================] - 4s 3ms/step - loss: 7.3024e-04 - r2: 0.9782 - explained_variance_score: 0.9784 - val_loss: 6.4234e-04 - val_r2: 0.9798 - val_explained_variance_score: 0.9798\n",
      "Epoch 53/100\n",
      "1066/1066 [==============================] - 4s 3ms/step - loss: 7.2142e-04 - r2: 0.9784 - explained_variance_score: 0.9786 - val_loss: 6.3945e-04 - val_r2: 0.9798 - val_explained_variance_score: 0.9800\n",
      "Epoch 54/100\n",
      "1066/1066 [==============================] - 4s 3ms/step - loss: 7.0905e-04 - r2: 0.9787 - explained_variance_score: 0.9789 - val_loss: 6.3685e-04 - val_r2: 0.9799 - val_explained_variance_score: 0.9800\n",
      "Epoch 55/100\n",
      "1066/1066 [==============================] - 4s 3ms/step - loss: 7.1307e-04 - r2: 0.9787 - explained_variance_score: 0.9788 - val_loss: 6.3106e-04 - val_r2: 0.9801 - val_explained_variance_score: 0.9802\n",
      "Epoch 56/100\n",
      "1066/1066 [==============================] - 4s 3ms/step - loss: 7.0865e-04 - r2: 0.9787 - explained_variance_score: 0.9788 - val_loss: 6.2486e-04 - val_r2: 0.9803 - val_explained_variance_score: 0.9804\n",
      "Epoch 57/100\n",
      "1066/1066 [==============================] - 4s 3ms/step - loss: 6.9092e-04 - r2: 0.9790 - explained_variance_score: 0.9792 - val_loss: 6.2236e-04 - val_r2: 0.9804 - val_explained_variance_score: 0.9805\n",
      "Epoch 58/100\n",
      "1066/1066 [==============================] - 4s 3ms/step - loss: 6.9154e-04 - r2: 0.9792 - explained_variance_score: 0.9794 - val_loss: 6.1448e-04 - val_r2: 0.9806 - val_explained_variance_score: 0.9807\n",
      "Epoch 59/100\n",
      "1066/1066 [==============================] - 4s 3ms/step - loss: 6.8258e-04 - r2: 0.9794 - explained_variance_score: 0.9796 - val_loss: 6.1047e-04 - val_r2: 0.9808 - val_explained_variance_score: 0.9808\n",
      "Epoch 60/100\n",
      "1066/1066 [==============================] - 4s 3ms/step - loss: 6.8233e-04 - r2: 0.9794 - explained_variance_score: 0.9796 - val_loss: 6.0623e-04 - val_r2: 0.9809 - val_explained_variance_score: 0.9810\n",
      "Epoch 61/100\n",
      "1066/1066 [==============================] - 4s 3ms/step - loss: 6.7374e-04 - r2: 0.9796 - explained_variance_score: 0.9798 - val_loss: 6.0255e-04 - val_r2: 0.9810 - val_explained_variance_score: 0.9811\n",
      "Epoch 62/100\n",
      "1066/1066 [==============================] - 4s 3ms/step - loss: 6.8132e-04 - r2: 0.9796 - explained_variance_score: 0.9798 - val_loss: 5.9748e-04 - val_r2: 0.9812 - val_explained_variance_score: 0.9813\n",
      "Epoch 63/100\n",
      "1066/1066 [==============================] - 4s 3ms/step - loss: 6.7237e-04 - r2: 0.9799 - explained_variance_score: 0.9801 - val_loss: 5.9461e-04 - val_r2: 0.9813 - val_explained_variance_score: 0.9813\n",
      "Epoch 64/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 6.6460e-04 - r2: 0.9799 - explained_variance_score: 0.9801 - val_loss: 5.9139e-04 - val_r2: 0.9814 - val_explained_variance_score: 0.9814\n",
      "Epoch 65/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 6.5906e-04 - r2: 0.9802 - explained_variance_score: 0.9804 - val_loss: 5.8685e-04 - val_r2: 0.9815 - val_explained_variance_score: 0.9816\n",
      "Epoch 66/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 6.5871e-04 - r2: 0.9803 - explained_variance_score: 0.9805 - val_loss: 5.8467e-04 - val_r2: 0.9816 - val_explained_variance_score: 0.9816\n",
      "Epoch 67/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 6.5993e-04 - r2: 0.9803 - explained_variance_score: 0.9804 - val_loss: 5.8029e-04 - val_r2: 0.9817 - val_explained_variance_score: 0.9818\n",
      "Epoch 68/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 6.4393e-04 - r2: 0.9806 - explained_variance_score: 0.9808 - val_loss: 5.7832e-04 - val_r2: 0.9818 - val_explained_variance_score: 0.9818\n",
      "Epoch 69/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 6.4394e-04 - r2: 0.9807 - explained_variance_score: 0.9808 - val_loss: 5.7447e-04 - val_r2: 0.9819 - val_explained_variance_score: 0.9820\n",
      "Epoch 70/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 6.4328e-04 - r2: 0.9806 - explained_variance_score: 0.9808 - val_loss: 5.7320e-04 - val_r2: 0.9819 - val_explained_variance_score: 0.9820\n",
      "Epoch 71/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 6.3979e-04 - r2: 0.9807 - explained_variance_score: 0.9809 - val_loss: 5.6850e-04 - val_r2: 0.9821 - val_explained_variance_score: 0.9822\n",
      "Epoch 72/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 6.3100e-04 - r2: 0.9809 - explained_variance_score: 0.9811 - val_loss: 5.6749e-04 - val_r2: 0.9821 - val_explained_variance_score: 0.9822\n",
      "Epoch 73/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 6.2566e-04 - r2: 0.9811 - explained_variance_score: 0.9813 - val_loss: 5.6312e-04 - val_r2: 0.9822 - val_explained_variance_score: 0.9823\n",
      "Epoch 74/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 6.2665e-04 - r2: 0.9812 - explained_variance_score: 0.9813 - val_loss: 5.5915e-04 - val_r2: 0.9824 - val_explained_variance_score: 0.9825\n",
      "Epoch 75/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 6.2843e-04 - r2: 0.9811 - explained_variance_score: 0.9813 - val_loss: 5.5849e-04 - val_r2: 0.9824 - val_explained_variance_score: 0.9825\n",
      "Epoch 76/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 6.2548e-04 - r2: 0.9812 - explained_variance_score: 0.9814 - val_loss: 5.5375e-04 - val_r2: 0.9825 - val_explained_variance_score: 0.9826\n",
      "Epoch 77/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 6.2413e-04 - r2: 0.9813 - explained_variance_score: 0.9815 - val_loss: 5.5159e-04 - val_r2: 0.9826 - val_explained_variance_score: 0.9827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 6.1980e-04 - r2: 0.9814 - explained_variance_score: 0.9815 - val_loss: 5.4915e-04 - val_r2: 0.9827 - val_explained_variance_score: 0.9828\n",
      "Epoch 79/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 6.1516e-04 - r2: 0.9816 - explained_variance_score: 0.9818 - val_loss: 5.4476e-04 - val_r2: 0.9828 - val_explained_variance_score: 0.9829\n",
      "Epoch 80/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 6.1580e-04 - r2: 0.9816 - explained_variance_score: 0.9818 - val_loss: 5.4380e-04 - val_r2: 0.9829 - val_explained_variance_score: 0.9829\n",
      "Epoch 81/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 6.0880e-04 - r2: 0.9816 - explained_variance_score: 0.9817 - val_loss: 5.4277e-04 - val_r2: 0.9829 - val_explained_variance_score: 0.9830\n",
      "Epoch 82/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 6.0639e-04 - r2: 0.9819 - explained_variance_score: 0.9820 - val_loss: 5.3831e-04 - val_r2: 0.9830 - val_explained_variance_score: 0.9831\n",
      "Epoch 83/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 6.0285e-04 - r2: 0.9819 - explained_variance_score: 0.9821 - val_loss: 5.3787e-04 - val_r2: 0.9830 - val_explained_variance_score: 0.9831\n",
      "Epoch 84/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 6.0371e-04 - r2: 0.9820 - explained_variance_score: 0.9821 - val_loss: 5.3548e-04 - val_r2: 0.9831 - val_explained_variance_score: 0.9832\n",
      "Epoch 85/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 5.9632e-04 - r2: 0.9820 - explained_variance_score: 0.9821 - val_loss: 5.3300e-04 - val_r2: 0.9832 - val_explained_variance_score: 0.9833\n",
      "Epoch 86/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 5.9376e-04 - r2: 0.9821 - explained_variance_score: 0.9822 - val_loss: 5.3071e-04 - val_r2: 0.9833 - val_explained_variance_score: 0.9833\n",
      "Epoch 87/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 5.8773e-04 - r2: 0.9822 - explained_variance_score: 0.9823 - val_loss: 5.2794e-04 - val_r2: 0.9834 - val_explained_variance_score: 0.9834\n",
      "Epoch 88/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 5.9039e-04 - r2: 0.9822 - explained_variance_score: 0.9823 - val_loss: 5.2502e-04 - val_r2: 0.9834 - val_explained_variance_score: 0.9835\n",
      "Epoch 89/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 5.8638e-04 - r2: 0.9824 - explained_variance_score: 0.9825 - val_loss: 5.2291e-04 - val_r2: 0.9835 - val_explained_variance_score: 0.9836\n",
      "Epoch 90/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 5.8384e-04 - r2: 0.9824 - explained_variance_score: 0.9825 - val_loss: 5.2221e-04 - val_r2: 0.9835 - val_explained_variance_score: 0.9836\n",
      "Epoch 91/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 5.7585e-04 - r2: 0.9826 - explained_variance_score: 0.9828 - val_loss: 5.2099e-04 - val_r2: 0.9836 - val_explained_variance_score: 0.9836\n",
      "Epoch 92/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 5.7556e-04 - r2: 0.9826 - explained_variance_score: 0.9827 - val_loss: 5.1896e-04 - val_r2: 0.9836 - val_explained_variance_score: 0.9837\n",
      "Epoch 93/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 5.7450e-04 - r2: 0.9827 - explained_variance_score: 0.9828 - val_loss: 5.1641e-04 - val_r2: 0.9837 - val_explained_variance_score: 0.9838\n",
      "Epoch 94/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 5.7988e-04 - r2: 0.9826 - explained_variance_score: 0.9827 - val_loss: 5.1475e-04 - val_r2: 0.9838 - val_explained_variance_score: 0.9838\n",
      "Epoch 95/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 5.7006e-04 - r2: 0.9827 - explained_variance_score: 0.9829 - val_loss: 5.1441e-04 - val_r2: 0.9838 - val_explained_variance_score: 0.9838\n",
      "Epoch 96/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 5.7556e-04 - r2: 0.9828 - explained_variance_score: 0.9829 - val_loss: 5.1020e-04 - val_r2: 0.9839 - val_explained_variance_score: 0.9840\n",
      "Epoch 97/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 5.6872e-04 - r2: 0.9828 - explained_variance_score: 0.9829 - val_loss: 5.0995e-04 - val_r2: 0.9839 - val_explained_variance_score: 0.9840\n",
      "Epoch 98/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 5.6852e-04 - r2: 0.9830 - explained_variance_score: 0.9831 - val_loss: 5.0673e-04 - val_r2: 0.9840 - val_explained_variance_score: 0.9841\n",
      "Epoch 99/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 5.6548e-04 - r2: 0.9831 - explained_variance_score: 0.9832 - val_loss: 5.0509e-04 - val_r2: 0.9841 - val_explained_variance_score: 0.9841\n",
      "Epoch 100/100\n",
      "1066/1066 [==============================] - 3s 3ms/step - loss: 5.5577e-04 - r2: 0.9832 - explained_variance_score: 0.9833 - val_loss: 5.0495e-04 - val_r2: 0.9841 - val_explained_variance_score: 0.9841\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "nb_epoch = 100 #ORiginally is minimally enough with 500\n",
    "batch_size = 32\n",
    "model.compile(optimizer='sgd', loss='mse',metrics=[r2,explained_variance_score])\n",
    "model.fit(X_train,X_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=nb_epoch,\n",
    "          validation_data=(X_test,X_test),\n",
    "          callbacks=[TensorBoard(log_dir='./data_set_55_conv/logs/')])\n",
    "model.save(\"./data_set_55_conv/autoencoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
